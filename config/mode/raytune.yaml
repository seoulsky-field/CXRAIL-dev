execute_mode: raytune

param_space:
  lr:
    _target_: ray.tune.loguniform
    lower: 0.00001
    upper: 0.001
  batch_size:
    _target_: ray.tune.choice
    categories:
      - 32
      - 64

  # weight_decay:
  #   _target_: ray.tune.loguniform
  #   lower: 0.0001
  #   upper: 0.1

  # rotate_degree:
  #   _target_: ray.tune.uniform
  #   lower: 10
  #   upper: 20

### Tuner ####
tune_config:
  _target_: ray.tune.TuneConfig
  search_alg:
    _target_: ray.tune.search.hyperopt.HyperOptSearch
    metric: val_score
    mode: max

  scheduler:
    _target_: ray.tune.schedulers.ASHAScheduler
    metric: val_score
    mode: max
    grace_period: 5

  num_samples: ${num_samples}

run_config:
  _target_: ray.air.RunConfig
  progress_reporter:
    _target_: ray.tune.CLIReporter
    parameter_columns: ${oc.dict.keys:mode.param_space}
    metric_columns:
      - epoch
      - Batch_ID
      - loss
      - val_loss
      - val_score
      - best_val_score
      - progress_of_epoch
  local_dir: ${log_dir}/${hydra:sweep.subdir}
  verbose: 2
  # callbacks: 
  #     - _target_: ray.air.callbacks.wandb.WandbLoggerCallback
  #       api_key: ${api_key}
  #       project: ${project_name}

# wandb: 1 #${mode.wandb}


